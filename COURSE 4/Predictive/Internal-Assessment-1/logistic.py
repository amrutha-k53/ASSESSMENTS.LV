# -*- coding: utf-8 -*-
"""Logistic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_hGnQdOWK8tSEA-S7BEusgcXJADh8TEu
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
df=pd.read_csv('/content/booking.csv')

df.head()

df.info()

df.describe()

df.isnull().sum()

df.duplicated().sum()

# Plot histograms for numerical columns
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

#bivariate analysis
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
# Compute the correlation matrix for numerical variables
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

"""Outlier detection"""

import seaborn as sns
avg_price_outliers = sns.boxplot(df['average price'])
df = df[df['average price']<200]

lead_time_outliers = sns.boxplot(df['lead time'])
df= df[df['lead time']<300]

df.info()

"""Remove Outliers"""

def remove_outliers(A,threshold):
 return df[A<threshold]
df=remove_outliers(df['average price'],200)
df=remove_outliers(df['lead time'],300)

"""Encoding"""

#encoding categorical features
from sklearn.preprocessing import LabelEncoder

lbl_enc = LabelEncoder()
df['type of meal'] = lbl_enc.fit_transform(df['type of meal'])
df['room type'] = lbl_enc.fit_transform(df['room type'])
df['market segment type'] = lbl_enc.fit_transform(df['market segment type'])
df['booking status'] = lbl_enc.fit_transform(df['booking status'])

#one hot encoding
label_encoder = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'object':
        df[column + '_encoded'] = label_encoder.fit_transform(df[column])

# Drop the original categorical columns
df.drop(columns=df.select_dtypes(include=['object']).columns, inplace=True)

"""Data Cleaning and Feature Selection"""

#fill null values
df['room type']=df['room type'].fillna(df['room type'].mode())
df['average price']=df['average price'].fillna(df['average price'].mean())

# Removing unnecessary columns (Feature selection)
book_data = df.drop(columns=['date of reservation','Booking_ID'],axis=1)

"""Train test split"""

from sklearn.model_selection import train_test_split

X =df.drop('booking status',axis=1)
y =df['booking status']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)

"""Build model"""

from sklearn.linear_model import LogisticRegression

regressor = LogisticRegression(random_state=0,max_iter=20000)

trained_model = regressor.fit(X_train,y_train)

y_pred = trained_model.predict(X_test)

"""Evaluation Metric"""

from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score

accuracy = accuracy_score(y_test,y_pred)
precision = precision_score(y_test,y_pred)
recall = recall_score(y_test,y_pred)
f1_score

print('Accuracy score: ',round(accuracy*100,2),'%')
print('Precision score: ',round(precision*100,2),'%')
print('Recall score: ',round(recall*100,2))